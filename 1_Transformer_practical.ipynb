{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b5f4f4-6f9c-4246-8970-0b595c822059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db3d8605-e195-473e-a16a-d66872d11982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dany\\.conda\\envs\\tfm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cad41868-4519-44b7-8fcc-c5fb45013bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('distilgpt2',output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "093d52af-4cef-4ad4-838f-f98fe6a75bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'kabhi khushi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d71c817f-387e-4338-ab19-091567284085",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(text,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7779b596-8e12-4a76-944e-d693100e422d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   74,   397,  5303, 44081, 17731]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee0a4a90-365e-4a99-afbc-7caa6b63fc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input,max_length=7,do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5030b671-a065-4e62-84cc-2e7eafc327a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   74,   397,  5303, 44081, 17731,   479,   283]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0894ca2b-fb21-4dbe-b4ef-2c46e410d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " kabhi khushi kar\n"
     ]
    }
   ],
   "source": [
    "print('\\n',tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "278fc5ed-f40a-4fea-86f7-e65ad932213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   74,   397,  5303, 44081, 17731,   479,   283]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4e11656-a29e-4fa6-8028-6fc732912704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   74,   397,  5303, 44081, 17731,   479,   283])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "191b612d-87c3-474a-afe2-1017bab5261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer(text,return_tensors='pt')['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "305cbd7c-0d66-47e0-b24c-9d9906851986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   74,   397,  5303, 44081, 17731]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57af589d-6029-4e67-a79d-7bf10796206c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k', 'ab', 'hi', 'Ä kh', 'ushi']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a9118a5-f55f-48ed-bff2-279f51d73ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50257, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6703cb19-fd7b-4b2e-9442-82ee478637d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a36deae7-06a5-4e59-a532-b355bdd04807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.3567e-02, -3.5492e-02,  8.9526e-02, -8.3440e-03,  1.2213e-01,\n",
       "         2.6488e-01, -2.7583e-01, -8.4173e-02,  9.3775e-02,  2.7267e-01,\n",
       "        -1.3663e-01,  9.4392e-02, -5.4182e-02,  5.2010e-02,  1.2742e-01,\n",
       "         2.0699e-01,  8.9082e-02,  2.3076e-02,  2.5875e-01,  1.0278e-01,\n",
       "         5.1171e-02, -3.8042e-02,  2.8455e-01,  4.5802e-01,  2.0700e-01,\n",
       "        -8.0535e-02, -5.1844e-02,  9.7817e-02,  4.0818e-03, -3.2785e-03,\n",
       "        -3.3026e-01, -3.8533e-01,  2.8358e-02,  7.8176e-02, -2.1908e-01,\n",
       "         1.5113e-01, -3.1548e-01, -2.1689e-03, -3.6411e-02,  5.6203e-02,\n",
       "         4.1375e-02,  7.1746e-02, -1.2743e-01, -1.1555e-01, -9.3855e-02,\n",
       "        -1.5175e-01, -1.5064e-02,  1.9065e-01,  8.3905e-02,  3.9262e-03,\n",
       "        -8.8730e-03, -3.0980e-03, -2.1613e-02, -7.0700e-02, -5.0771e-02,\n",
       "        -3.0079e-02, -2.1463e-01,  5.0632e-02,  8.2793e-02, -7.9612e-03,\n",
       "        -5.3502e-02,  2.9217e-01, -2.6620e-01,  1.3850e-01,  1.6574e-01,\n",
       "         2.4321e-02, -1.1191e-01, -1.8630e-01,  1.7976e-01,  5.7515e-02,\n",
       "        -1.2311e-01,  4.8979e-02, -4.3406e-02,  2.1488e-01,  2.1263e-01,\n",
       "         4.8566e-02, -3.4714e-02,  1.1078e-01, -9.7570e-02, -1.1482e-01,\n",
       "        -2.7903e-02,  5.6817e-02,  1.5416e-02, -7.7676e-02,  1.7216e-02,\n",
       "        -6.6511e-02, -2.2010e-01,  1.2995e-01,  9.8774e-02, -8.7821e-02,\n",
       "        -3.5570e-02, -7.4647e-02, -5.5278e-03,  1.3655e-01,  1.3908e-01,\n",
       "        -1.6455e-01,  8.3557e-02,  7.1359e-02, -2.1549e-02, -1.6938e-01,\n",
       "        -3.4533e-01, -2.8413e-03, -2.1513e-02, -2.1443e-01,  2.0519e-01,\n",
       "        -5.3627e-02, -2.6343e-02, -1.2175e-01, -8.0023e-02, -1.7348e-01,\n",
       "         1.0030e-01, -2.3190e-01,  3.6211e-02,  2.0862e-01,  1.1653e-02,\n",
       "         1.0681e-01,  9.7692e-02, -1.5699e-01,  1.4070e-01, -4.8606e-02,\n",
       "         2.5402e-01, -6.1452e-02, -4.3367e-02, -1.2315e-01,  1.5214e-01,\n",
       "        -8.0992e-02, -5.7841e-03,  1.9040e-01, -1.0707e-01,  9.6015e-02,\n",
       "         2.6037e-01, -6.5857e-02, -1.5466e-01, -7.7017e-02, -2.6140e-01,\n",
       "         6.9810e-02, -2.9120e-01, -9.5420e-02, -8.1057e-02, -2.3481e-01,\n",
       "         3.5538e-02,  1.0669e-01,  8.6821e-02,  1.2085e-01, -1.6000e-01,\n",
       "        -1.2582e-01, -1.8966e-01,  1.9114e-01, -1.1915e-01,  9.4060e-02,\n",
       "        -1.0877e-01, -2.0782e-01,  7.2845e-03,  5.2271e-02, -8.1806e-02,\n",
       "         2.4248e-01,  1.0175e-01,  3.1081e-02,  1.8467e-01, -4.1279e-02,\n",
       "        -1.4148e-01, -7.8725e-02, -1.4021e-02,  1.8306e-01,  2.7670e-03,\n",
       "         8.3448e-02,  1.1179e-04,  2.4804e-01, -8.4713e-02, -3.7300e-02,\n",
       "        -8.7019e-02,  7.5753e-02,  8.3621e-02,  1.2095e-01,  2.2177e-01,\n",
       "        -6.5061e-03,  2.3285e-01,  1.3718e-01,  8.3217e-02,  1.7847e-01,\n",
       "        -2.9066e-02, -1.1654e-01,  3.7242e-01, -1.3447e-02, -2.3497e-01,\n",
       "         3.8656e-02,  6.3717e-02, -9.4516e-02,  8.3166e-02, -6.9221e-02,\n",
       "        -2.2240e-01, -3.9649e-02, -1.3441e-01, -1.0039e-01,  3.0905e-01,\n",
       "         1.7607e-01, -8.7765e-02, -1.5323e-01, -1.3625e-01,  1.8987e-01,\n",
       "        -6.2727e-02, -5.9288e-02,  1.4347e-01,  1.3936e-01, -5.2830e-02,\n",
       "         1.5417e-01,  3.3350e-01,  1.0155e-02, -2.0396e-01, -8.5957e-02,\n",
       "         1.0591e-01,  1.0035e-01,  1.4059e-01, -7.6604e-02, -2.6852e-01,\n",
       "         2.8213e-01, -3.0071e-02, -8.2186e-02,  1.4451e-01, -1.8746e-01,\n",
       "         1.7302e-01, -5.3060e-02,  1.9814e-01, -2.2653e-01, -2.2684e-01,\n",
       "        -1.6011e-03,  1.0374e-01,  1.6167e-02,  2.4142e-02, -3.9675e-02,\n",
       "        -1.3650e-01, -3.9362e-02, -1.3561e-01, -1.3449e-01, -1.6902e-01,\n",
       "        -3.1370e-02, -2.0408e-01,  1.6015e-01,  1.9586e-01, -1.8087e-01,\n",
       "         3.3364e-02,  8.9389e-02,  1.1729e-03,  4.5512e-02, -3.7798e-01,\n",
       "        -5.6412e-02, -8.0390e-02,  8.2606e-03, -1.1011e-01, -4.6707e-02,\n",
       "         1.2198e-01,  8.1134e-02, -2.6743e-02,  6.9517e-02,  1.2032e-01,\n",
       "        -1.9027e-01,  8.0616e-02, -2.3213e-01, -6.6173e-02, -6.8056e-02,\n",
       "         7.4445e-03, -6.8209e-02,  1.2614e-01, -1.3024e-02,  9.8023e-02,\n",
       "         3.6065e-01,  1.2536e-01, -2.7965e-01, -2.4594e-02,  1.7614e-02,\n",
       "         1.4665e-01, -2.3296e-01, -2.0014e-01, -6.2488e-02, -8.5105e-02,\n",
       "         2.9068e-01, -1.1629e-01,  6.5682e-02,  1.1452e-01,  8.4365e-02,\n",
       "        -1.1914e-01, -1.6402e-01, -8.8764e-02,  7.7260e-02,  1.0720e-01,\n",
       "        -1.3655e-01,  3.1078e-01,  1.4143e-01, -1.6542e-01,  1.8333e-01,\n",
       "        -3.9254e-02, -1.1742e-01,  9.1268e-02,  6.0848e-02, -3.6935e-02,\n",
       "         8.3408e-02, -4.7256e-02, -1.4251e-01,  6.3580e-02,  1.6748e-01,\n",
       "        -2.0392e-02, -1.0431e-01, -1.2282e-01, -1.1546e-01,  3.5418e-02,\n",
       "        -3.4817e-01,  1.7660e-01,  3.4101e-01,  1.9102e-01,  1.4412e-01,\n",
       "        -5.4182e-02, -4.7210e-02, -7.1313e-02,  2.0729e-02,  2.0027e-01,\n",
       "        -1.2779e-01,  7.4857e-02,  4.5106e-02, -5.5216e-03, -9.8283e-02,\n",
       "         1.9846e-01,  2.5100e-01,  2.8688e-01, -1.9516e-01, -1.3185e-01,\n",
       "        -2.7785e-01, -2.7423e-01, -2.0669e-01,  1.1196e-01, -9.6900e-02,\n",
       "        -2.1433e-02, -2.0211e-01, -2.7114e-02, -1.4565e-01, -1.9078e-02,\n",
       "        -8.0379e-02, -1.8946e-02,  2.5758e-01,  3.1330e-01,  8.1900e-02,\n",
       "         8.5319e-02,  5.6614e-02, -4.9184e-02,  1.7807e-02, -1.1212e-01,\n",
       "         8.4277e-02, -1.4514e-01,  5.6470e-02,  8.9964e-02, -1.7929e-01,\n",
       "         3.3502e-02, -1.5370e-01, -3.3569e-02,  1.8471e-02, -7.8822e-02,\n",
       "        -1.2175e-01, -1.3235e-01,  2.7808e-01, -6.7108e-02,  2.9836e-02,\n",
       "        -2.3259e-03, -1.7663e-02, -5.2430e-01,  2.3847e-01,  2.4659e-01,\n",
       "         1.8278e-01, -1.8338e-01,  1.0202e-01, -2.0881e-02, -4.7346e-02,\n",
       "        -5.7924e-02,  2.0976e-02,  1.5227e-01,  1.4022e-01,  1.8022e-01,\n",
       "         9.9243e-03, -6.9925e-02,  2.6602e-02, -7.8807e-02,  1.5059e-01,\n",
       "         1.9179e-01, -1.4627e-01, -1.1429e-01,  1.4098e-01,  1.4773e-01,\n",
       "        -1.3751e-01, -1.8642e-01,  6.9907e-02, -1.6945e-01,  3.5635e-01,\n",
       "        -1.0468e-01, -1.5515e-01,  1.5984e-02,  4.4723e-02,  3.6308e-02,\n",
       "         5.3691e-02, -4.7399e-02, -2.4812e-02, -1.5008e-01,  8.5374e-02,\n",
       "         1.4532e-01, -1.7606e-01, -5.3098e-02,  7.7118e-02, -1.3183e-01,\n",
       "        -1.3461e-01,  6.5817e-02,  2.0649e-01, -3.5359e-01,  1.3998e-01,\n",
       "         5.8057e-02,  5.2679e-02, -2.9940e-01,  4.1405e-02,  9.3618e-02,\n",
       "         8.3238e-02,  2.0990e-01, -1.2793e-01, -2.2074e-01,  4.0223e-02,\n",
       "         8.4626e-02,  1.6820e-01, -2.4169e-01, -1.8260e-02,  1.5322e-01,\n",
       "         1.7242e-01, -1.6071e-01, -2.7921e-01, -3.2898e-03, -2.8300e-02,\n",
       "        -2.5714e-01, -2.6985e-01,  1.6506e-01,  3.4092e-01, -2.4330e-01,\n",
       "        -1.5165e-01, -4.6975e-02, -2.8833e-01, -6.6280e-02, -4.8153e-02,\n",
       "        -1.3179e-02,  6.0172e-02, -1.5185e-01,  4.6051e-02, -1.9368e-01,\n",
       "        -6.0417e-02, -2.2529e-01, -1.0193e-01, -3.6343e-02,  5.8305e-02,\n",
       "        -3.4742e-02, -4.6445e-02,  1.2163e-01,  1.9144e-01, -5.0810e-01,\n",
       "        -1.8521e-01,  1.2817e-01,  9.7172e-02,  2.3957e-01, -2.0126e-01,\n",
       "        -4.3952e-02,  1.1342e-01,  3.8496e-02, -4.1571e-02,  2.0843e-01,\n",
       "         1.1637e-01,  1.1756e-01, -1.9740e-02,  5.4005e-03,  7.4631e-02,\n",
       "        -8.4651e-02,  8.9300e-02,  2.0692e-01, -1.1841e-01, -5.7971e-02,\n",
       "        -1.0061e-01,  5.0501e-01,  2.1331e-02, -1.2301e-02,  1.5549e-01,\n",
       "         8.2508e-02, -1.6301e-01, -2.4556e-02,  1.0349e-02, -1.3489e-01,\n",
       "         4.7641e-02, -1.2918e-01,  2.5816e-01, -4.3216e-03,  6.1607e-02,\n",
       "        -6.7034e-02,  2.7672e-02, -3.7096e-02, -1.4839e-01,  1.3278e-01,\n",
       "        -7.3423e-03, -2.0733e-01,  2.4023e-01, -8.6889e-02, -9.6696e-02,\n",
       "        -1.8363e-01,  1.7993e-01,  5.5282e-02,  1.1062e-01, -2.6507e-01,\n",
       "         1.0973e-01,  1.3014e-03,  1.8291e-02,  8.0923e-03,  7.4847e-03,\n",
       "        -6.2169e-03,  6.7223e-02, -1.0822e-01, -1.7438e-04,  4.4995e-02,\n",
       "         1.1898e-02, -2.0129e-01,  2.2171e-01,  5.3124e-02,  2.3297e-01,\n",
       "        -1.6929e-01, -1.4170e-01, -2.3578e-02,  6.0694e-02, -3.9564e-02,\n",
       "        -4.0554e-02,  3.0799e-01,  3.4008e-01,  4.7238e-02, -2.3022e-01,\n",
       "        -2.9669e-01, -7.7921e-02,  2.0457e-01,  1.0979e-01,  8.8640e-02,\n",
       "         3.7265e-02, -3.1955e-01, -2.0592e-01, -4.0272e-02,  1.3684e-01,\n",
       "        -1.0802e-02, -9.1178e-02,  1.2620e-01,  1.1762e-01,  1.3865e-01,\n",
       "         1.5316e-01,  1.9407e-01, -3.2871e-01, -5.1666e-02,  2.1011e-02,\n",
       "         1.2824e-01, -2.9469e-01, -4.3328e-02, -2.0090e-01,  2.3430e-01,\n",
       "        -1.3756e-02, -1.6073e-01,  3.5305e-03, -5.5105e-02,  2.2062e-01,\n",
       "         1.7823e-01, -2.4353e-02,  1.1651e-01,  2.3165e-01, -1.6456e-01,\n",
       "         2.7362e-02, -2.5224e-01, -1.3487e-01, -1.2068e-01,  2.4308e-01,\n",
       "        -4.1030e-03, -1.4334e-01, -7.0580e-02,  4.9683e-01,  1.3869e-01,\n",
       "        -2.4611e-01,  1.6593e-01,  8.4644e-02,  5.2035e-02,  1.7726e-01,\n",
       "        -3.6489e-02, -9.6178e-02, -1.2522e-01,  5.5939e-02,  5.0217e-02,\n",
       "        -1.1083e-01,  4.4723e-02,  5.8107e-02, -5.0366e-02, -1.9296e-02,\n",
       "         2.9105e-01, -1.5850e-01, -1.2968e-01, -6.8352e-02, -1.2625e-01,\n",
       "         9.3949e-02, -7.5606e-02, -1.4019e-01, -3.5897e-03, -1.4825e-01,\n",
       "         1.3795e-02, -1.3321e-01, -1.7689e-02,  1.6395e-01, -5.5799e-02,\n",
       "         1.6704e-01, -8.5020e-02,  2.7192e-01, -3.5989e-01, -2.9615e-01,\n",
       "         3.7501e-01,  1.6762e-01, -2.0982e-01, -1.1810e-01, -1.5618e-01,\n",
       "        -2.4834e-01, -1.8550e-01,  1.3917e-01,  2.1470e-01,  1.5941e-01,\n",
       "        -3.8011e-03, -7.8896e-02, -2.6428e-01,  1.2531e-01,  1.5865e-01,\n",
       "         1.3480e-01,  6.0266e-02,  2.3416e-01,  1.0559e-02,  1.7208e-01,\n",
       "        -1.1126e-02, -2.5939e-02, -3.6027e-02,  1.9880e-02,  9.6473e-02,\n",
       "         8.3611e-02,  8.4939e-02, -1.0733e-01, -1.5775e-01,  3.3897e-01,\n",
       "        -1.2377e-01, -6.9476e-02,  4.4556e-02,  2.1160e-01, -5.2148e-02,\n",
       "        -7.1205e-02,  2.6356e-01,  5.5348e-02,  4.5908e-02,  2.2381e-01,\n",
       "        -1.1807e-01, -7.7701e-02, -4.6318e-02,  2.5752e-01,  4.1610e-01,\n",
       "        -1.9757e-01, -7.9055e-02, -1.5968e-01,  3.6631e-02, -1.1746e-01,\n",
       "        -9.4631e-03,  5.8896e-02,  1.9478e-01, -2.0086e-01,  3.4372e-01,\n",
       "        -4.4178e-02,  1.7299e-02, -1.4280e-01, -2.6379e-01, -2.0196e-01,\n",
       "         1.5570e-01,  1.5914e-01,  1.6006e-01,  1.0523e-01,  1.2840e-01,\n",
       "        -3.4830e-01, -3.6966e-02, -8.3431e-02,  1.2392e-02, -1.8572e-01,\n",
       "         5.0236e-02,  3.2687e-02, -1.6275e-01,  1.7649e-01,  3.7541e-02,\n",
       "         1.6046e-01, -1.8876e-01,  6.9609e-02, -1.5907e-01,  8.6109e-02,\n",
       "         7.8457e-02,  1.7767e-01,  7.0176e-02,  2.6973e-01, -4.0461e-02,\n",
       "        -6.3210e-02, -2.1727e-02,  2.0835e-02, -1.1870e-01, -2.3684e-02,\n",
       "         9.2990e-02,  7.4863e-02,  2.8833e-02,  1.5246e-01,  6.5005e-02,\n",
       "         1.8029e-01,  1.2302e-01, -8.0531e-02, -2.1365e-01,  2.7639e-01,\n",
       "         6.0546e-02, -1.5087e-01, -1.7642e-01, -9.5107e-02, -1.5907e-01,\n",
       "        -5.2020e-02, -1.9476e-01, -3.2430e-03, -1.7693e-01, -6.9185e-02,\n",
       "        -1.9485e-01,  1.5382e-01,  1.4238e-01, -1.4514e-01, -4.2110e-02,\n",
       "        -4.4471e-02, -2.9200e-01, -1.8833e-01,  2.4524e-01, -7.9774e-02,\n",
       "        -1.1641e-01, -2.7984e-01, -2.2487e-01,  8.8063e-02, -2.8070e-01,\n",
       "         2.6909e-01, -9.0178e-02, -9.1513e-02, -3.7062e-02,  1.9759e-01,\n",
       "         1.1097e-01, -1.8554e-01, -1.7487e-01,  2.0795e-01,  2.0790e-01,\n",
       "         2.9636e-01,  3.9303e-02,  1.2832e-01,  2.8750e-02, -1.4825e-01,\n",
       "        -2.1401e-01, -1.0781e-01, -1.7810e-01, -1.1899e-01,  2.5067e-01,\n",
       "        -1.9685e-01, -3.7956e-02, -2.4066e-01,  3.9103e-02, -1.1155e-01,\n",
       "        -5.4421e-02,  2.7806e-01, -2.4291e-01,  1.4710e-02,  3.1491e-01,\n",
       "         2.5611e-02,  2.9547e-02,  2.5821e-01], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.transformer.wte(torch.tensor(5303))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3568530-345d-4d9b-8a95-3800580ee2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'The chiken did not cross the road because it was'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a1c8093-d540-42b3-8e3c-f21223050192",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tokenizer.encode(text,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "305aad34-b037-440a-a8cb-86850985fa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  464,   442, 29943,   750,   407,  3272,   262,  2975,   780,   340,\n",
       "           373]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b24bc849-d595-43df-97e7-47205b1712d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(input,max_length=30,do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "564465d1-25db-4c3d-b770-0c79feaa1b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  464,   442, 29943,   750,   407,  3272,   262,  2975,   780,   340,\n",
       "           373,   257,   845,  8468,   779,    13,   198,   464,   442, 29943,\n",
       "           373,   407,   257,  3704,   286,  3348,   475,   257,  3912,    11]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d88369e-4469-4680-a346-f863edb4917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The chiken did not cross the road because it was a very unusual use.\n",
      "The chiken was not a piece of paper but a pattern,\n"
     ]
    }
   ],
   "source": [
    "print('\\n',tokenizer.decode(output[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
